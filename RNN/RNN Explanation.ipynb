{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptions are based on the awesome lecture provided by [Andrej Karpathy](https://www.youtube.com/watch?v=yCC09vCHzF8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Networks offer a lot of flexibility\n",
    "![Types](./Images/types.png)\n",
    "\n",
    "* **One to One:** A fixed-sized input vector (Red) process the image with some hidden layers (Green) and produces a fixed-size output vector (Blue)\n",
    "* **One to many:** e.g. **Image captioning**. Image -> sequence of words that describes the content of the image.\n",
    "* **Many to One:** e.g. **Sentiment Classification (In NLP)**. sequence of words -> sentiment (Sentence is positive or negative).\n",
    "* **Many To Many:** e.g. **Machine Translation**. Seq of words (English) -> Seq of words (Persian)\n",
    "* **Many To Many(Last case):** e.g. Video Classification. Classifying every single frame of a video with some number of classes but the prediction at every single time step is a function of all the frames that have come in up to that point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified RNN Box\n",
    "![Simplified RNN Box Image](Images/SimplifiedRNNBox.png)\n",
    "\n",
    "RNN is basically this green box and it has a state. Over time, it recieves input vectors. So every single time we can feed in an input vector into the RNN and it has some state internally and then it can modify that state as a function of what it receives at every single time step. So they're weights inside this RNN and when we tune those weights the RNN will have different behavior in terms of how its state evolves as it receives these inputs.\n",
    "\n",
    "Usually we also be interested in poducing an output based on the RNN state so we can produce these vectors on top of the RNN.\n",
    "\n",
    "We can denote this state as a vector $h_{t}$ or a collection of vectors. Then, we're going to base it as a function of the previous hidden state at previous iteration time (t-1) and current input vector $x_{t}$ and say that:\n",
    "$$h_{t} = f_{w}(h_{t-1},x_{t})$$\n",
    "* $h_{t}$: new state\n",
    "* $f_{w}$: recurrence function\n",
    "* $h_{t-1}$: old state\n",
    "* $x_{t}$: input vector at some time step\n",
    "\n",
    "As we change the W in $f_{w}$, we see that RNN will have different behaviors. Hence, we can train those weights on data\n",
    "\n",
    "**Important:** the same function is used at every single time step. We have this fixed function of weights W and we applied that single function at every single time step and that allows us to use the kernel network on sequences without having to commit to the size of the sequence because we apply the exact same function at every single time step.**No matter how long the input or output sequences are.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla RNN\n",
    "the simplest way we can set this up is by setting just a single hidden state H and then we have a recurrence formula that basically informs us how we should update this hidden state H as a function of the previous hidden state and the current input $x_{t}$.\n",
    "\n",
    "In the simplest case, we're going to have these weight matrices $w_{hh}$ and $w_{xh}$. They're both going to project the hidden state from the previous time step and current input and then those are going to add and then we squash them with a tanh. \n",
    "$$h_{t} = tanh(w_{hh}h_{t-1} + w_{xh}x_{t})$$\n",
    "\n",
    "Then we can base predictions on top of H. For example using just another matrix projection on top of the hidden state. So this is the simplest complete case in which we can wire up a NN.\n",
    "$$y_{t} = w_{hy}h_{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One RNN Application\n",
    "### Character-level language model\n",
    "In this application, we will feed a sequence of characters into the RNN and at every single time step we ask the RNN to predict the next character in the sequence. So a prediction of entire distribution for what it thinks should come next in the sequence that it has seen so far.\n",
    "\n",
    "Example training sequence: **\"hello\"**  \n",
    "Vocabulary: [h, e, l, o]\n",
    "\n",
    "In the example above, we have the training sequence **\"hello\"**, so we have the vocabulary of four characters. Now, we're going to try to get a RNN to learn to predict the next character in a sequence on this training data.  \n",
    "![Character-level language model](Images/char_level_language_model.png)\n",
    "On the picture above, the x axis is time, and on the input layer, we use [One-hot encoding](https://en.wikipedia.org/wiki/One-hot). This encoders set a bit for each vocabulary based on its index.  \n",
    "\n",
    "Then we use the recurrence formula. Such that $h_{t-1}$ in the first step is all zero. Then we apply this recurrence to compute the hidden state vector at every single time step using the fixed recurrence formula. So suppose here we have only three numbers in the hidden state (the three number we can see on each green block). We're going to end up with a three dimensional representation that basically at any point in time, summarizes all the characters that have come until then. So we apply this recurrence at every single time step and now we're going to predict at every single time step what should be the next character in the sequence.\n",
    "\n",
    "Since we have four characters in this vocabulary, we're going to predict four numbers at every single time step (numbers in blue blocks). For instance, in the very first time step we fed in the letter 'h' and the RNN with it's current setting of weights computes the unnormalized lock probabilities we can see at the first blue block (for what should come next).\n",
    "\n",
    "We know that after 'h' in \"hello\" comes 'e'. So 2.2 for 'e' is the correct answer since it has the highest value. So every single time step we have a target for what next character should come in the sequence and so we just want all those numbers to be high and all the other numbers to be low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codes are based on [this tutorial](https://www.youtube.com/watch?v=Gl2WXLIMvKA&list=PLhhyoLH6IjfxeoooqP9rhU3HJIAVAJ3Vz&index=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F  # Functions without parameters such as relu, tanh, ...\n",
    "from torch.utils.data import DataLoader  # Dataset management. It helps us create mini-batches to train and ..\n",
    "import torchvision.datasets as datasets  # Datasets such as MNIST\n",
    "import torchvision.transforms as transforms  # transformations that we can do on our datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally we don't use RNN for images but here we do for the sake of learning it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        \"\"\"\n",
    "        We don't have to explicitly say how many sequences we want to have. RNN works for any number of sequences\n",
    "        that we send in.\n",
    "        \"\"\"\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_classes, batch_first=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image is 28x28. We consider it as 28 sequences each has 28 features\n",
    "input_size = 28 \n",
    "sequence_length = 28\n",
    "\n",
    "num_layers = 2\n",
    "hidden_size = 256\n",
    "\n",
    "num_classes = 10\n",
    "learning_rate = 0.001 \n",
    "batch_size = 64\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is based on [this video on Youtube](https://www.youtube.com/watch?v=u1loyDCoGbE). However, in the concatination part, I guess there was a mistake and mine is different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "According to the [original paper](https://arxiv.org/pdf/1505.04597.pdf), U-Net has the following architecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv(in_c, out_c):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_c, out_c, kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_c, out_c, kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    \n",
    "    return conv\n",
    "\n",
    "def crop_image(tensor, target_tensor):\n",
    "    target_size = target_tensor.size()[2]  # since height and width are the same we just get one of them\n",
    "    tensor_size = tensor.size()[2]\n",
    "    \n",
    "    delta = tensor_size - target_size\n",
    "    delta = delta // 2\n",
    "    return tensor[:, :, delta:tensor_size-delta, delta:tensor_size-delta]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "    \n",
    "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.down_conv_1 = double_conv(in_c=1, out_c=64)\n",
    "        self.down_conv_2 = double_conv(in_c=64, out_c=128)\n",
    "        self.down_conv_3 = double_conv(in_c=128, out_c=256)\n",
    "        self.down_conv_4 = double_conv(in_c=256, out_c=512)\n",
    "        self.down_conv_5 = double_conv(in_c=512, out_c=1024)\n",
    "        \n",
    "        self.up_trans_1 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=2, stride=2)\n",
    "        self.up_conv_1 = double_conv(1024, 512)\n",
    "        \n",
    "        self.up_trans_2 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\n",
    "        self.up_conv_2 = double_conv(512, 256)\n",
    "        \n",
    "        self.up_trans_3 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2)\n",
    "        self.up_conv_3 = double_conv(256, 128)\n",
    "        \n",
    "        self.up_trans_4 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2)\n",
    "        self.up_conv_4 = double_conv(128, 64)\n",
    "        \n",
    "        self.out = nn.Conv2d(in_channels=64, out_channels=2, kernel_size=1)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        # encoder\n",
    "        x1 = self.down_conv_1(image)\n",
    "        x2 = self.max_pool_2x2(x1)\n",
    "        x3 = self.down_conv_2(x2)\n",
    "        x4 = self.max_pool_2x2(x3)\n",
    "        x5 = self.down_conv_3(x4)\n",
    "        x6 = self.max_pool_2x2(x5)\n",
    "        x7 = self.down_conv_4(x6)\n",
    "        x8 = self.max_pool_2x2(x7)\n",
    "        x9 = self.down_conv_5(x8)\n",
    "        \n",
    "        # decoder\n",
    "        x = self.up_trans_1(x9)\n",
    "        y = crop_image(x7, x)\n",
    "        x= self.up_conv_1(torch.cat([y, x], 1))\n",
    "        \n",
    "        x = self.up_trans_2(x)\n",
    "        y = crop_image(x5, x)\n",
    "        x= self.up_conv_2(torch.cat([y, x], 1))\n",
    "        \n",
    "        x = self.up_trans_3(x)\n",
    "        y = crop_image(x3, x)\n",
    "        x= self.up_conv_3(torch.cat([y, x], 1))\n",
    "        \n",
    "        x = self.up_trans_4(x)\n",
    "        y = crop_image(x1, x)\n",
    "        x= self.up_conv_4(torch.cat([y, x], 1))\n",
    "        \n",
    "        x = self.out(x)\n",
    "        print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 388, 388])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0878, -0.0815, -0.0852,  ..., -0.0897, -0.0931, -0.0906],\n",
       "          [-0.0901, -0.0884, -0.0810,  ..., -0.0904, -0.0924, -0.0922],\n",
       "          [-0.0851, -0.0866, -0.0827,  ..., -0.0863, -0.0861, -0.0853],\n",
       "          ...,\n",
       "          [-0.0880, -0.0945, -0.0859,  ..., -0.0874, -0.0870, -0.0894],\n",
       "          [-0.0842, -0.0904, -0.0843,  ..., -0.0883, -0.0858, -0.0882],\n",
       "          [-0.0854, -0.0866, -0.0877,  ..., -0.0903, -0.0891, -0.0875]],\n",
       "\n",
       "         [[ 0.1151,  0.1043,  0.1113,  ...,  0.1104,  0.1162,  0.1118],\n",
       "          [ 0.1042,  0.1121,  0.1069,  ...,  0.1090,  0.1061,  0.1080],\n",
       "          [ 0.1111,  0.1045,  0.1015,  ...,  0.1131,  0.1091,  0.1105],\n",
       "          ...,\n",
       "          [ 0.1083,  0.1031,  0.1060,  ...,  0.1068,  0.1068,  0.1038],\n",
       "          [ 0.1115,  0.1067,  0.1068,  ...,  0.1082,  0.1085,  0.1106],\n",
       "          [ 0.1010,  0.1072,  0.1100,  ...,  0.1107,  0.1113,  0.0950]]]],\n",
       "       grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.rand((1, 1, 572, 572))  # batch_size=1, channel=1, width & height = 572\n",
    "model = UNet()\n",
    "model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
